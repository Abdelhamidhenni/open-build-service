#!/usr/bin/perl -w
#
# Copyright (c) 2006, 2007 Michael Schroeder, Novell Inc.
# Copyright (c) 2008 Adrian Schroeter, Novell Inc.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License version 2 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program (see the file COPYING); if not, write to the
# Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA
#
################################################################
#
# The Scheduler. One big chunk of code for now.
#

BEGIN {
  my ($wd) = $0 =~ m-(.*)/- ;
  $wd ||= '.';
  unshift @INC,  "$wd/build";
  unshift @INC,  "$wd";
}

use Digest::MD5 ();
use Data::Dumper;
use Storable ();
use XML::Structured ':bytes';
use POSIX;
use Fcntl qw(:DEFAULT :flock);

use BSConfiguration;
use BSRPC ':https';
use BSUtil;
use BSFileDB;
use BSXML;
use BSDBIndex;
use BSBuild;
use BSVerify;
use Build;
use BSDB;
use BSSolv;
use BSCando;

use BSSched::RPC;
use BSSched::Remote;
use BSSched::DoD;
use BSSched::ProjPacks;
use BSSched::BuildRepo;
use BSSched::BuildResult;
use BSSched::PublishRepo;
use BSSched::Events;
use BSSched::BuildJob;
use BSSched::Access;
use BSSched::Lookat;

use BSSched::BuildJob::Aggregate;
use BSSched::BuildJob::Channel;
use BSSched::BuildJob::DeltaRpm;
use BSSched::BuildJob::KiwiImage;
use BSSched::BuildJob::KiwiProduct;
use BSSched::BuildJob::Package;
use BSSched::BuildJob::Patchinfo;
use BSSched::BuildJob::PreInstallImage;
use BSSched::BuildJob::SimpleImage;
use BSSched::BuildJob::Unknown;

if ($BSConfig::enable_download_on_demand) {
  require BSDoD;
}

use strict;

my $testprojid;
my $testmode;
my $asyncmode;
my $startupmode;

$asyncmode = $BSConfig::sched_asyncmode if $BSConfig::sched_asyncmode;
$startupmode = $BSConfig::sched_startupmode if $BSConfig::sched_startupmode;

my $bsdir = $BSConfig::bsdir || "/srv/obs";

my @binsufs = qw{rpm deb pkg.tar.gz pkg.tar.xz};
my $binsufsre = join('|', map {"\Q$_\E"} @binsufs);

BSUtil::mkdir_p_chown($bsdir, $BSConfig::bsuser, $BSConfig::bsgroup);
BSUtil::drop_privs_to($BSConfig::bsuser, $BSConfig::bsgroup);

BSUtil::set_fdatasync_before_rename() unless $BSConfig::disable_data_sync || $BSConfig::disable_data_sync;

my $_reporoot = "$bsdir/build";
my $_jobsdir = "$bsdir/jobs";
my $_eventdir = "$bsdir/events";
my $_extrepodir = "$bsdir/repos";
my $_dodsdir = "$bsdir/dods";
my $_rundir = $BSConfig::rundir || "$bsdir/run";
my $infodir = "$bsdir/info";
my $_remotecache = "$BSConfig::bsdir/remotecache";

if (@ARGV && $ARGV[0] eq '--testmode') {
  $testmode = 1;
  shift @ARGV;
}
if (@ARGV && ($ARGV[0] eq '--exit' || $ARGV[0] eq '--stop')) {
  $testmode = 'exit';
  shift @ARGV;
} elsif (@ARGV && $ARGV[0] eq '--restart') {
  $testmode = 'restart';
  shift @ARGV;
}

my $_myarch = $ARGV[0] || 'i586';

if (!$BSCando::knownarch{$_myarch}) {
  die("Architecture '$_myarch' is unknown, please adapt BSCando.pm\n");
}

my %_remoteprojs;	# remote project cache

# Create directory on first start
mkdir_p($infodir) || die ("failed to create $infodir\n");

my %_prpcheckuseforbuild;	# project/package meta has changed
my %_channeldata;	# global channel data unificator to save memory

#  'lastscan'   last time we scanned
#  'meta'       meta cache
#  'solv'       solv data cache (for remote repos)
my %_repodatas;		# our repository knowledge
my %_repodatas_alien;	# repositories from other archs

my %_remotegbininfos;
my %_remotepackstatus;
my %_remotepackstatus_cleanup;


#######################################################################
#######################################################################
##
## Repository management functions
##


sub set_repo_state {
  my ($gctx, $prp, $state, $details) = @_;

  my $myarch = $gctx->{'arch'};
  my $reporoot = $gctx->{'reporoot'};
  my $gdst = "$reporoot/$prp/$myarch";
  unlink("$gdst/:schedulerstate.dirty") if $state eq 'scheduling' || $state eq 'broken' || $state eq 'disabled';
  $state .= " $details" if $details;
  mkdir_p($gdst);
  writestr("$gdst/.:schedulerstate", "$gdst/:schedulerstate", $state);
}


####################################################################
####################################################################
##
##  project/package data collection functions
##

#my @prps;		# all prps(project-repositories-sorted) we have to schedule, sorted
#my %prpsearchpath;	# maps prp => [ prp, prp, ...]
                        # build packages with the packages of the prps
#my %prpdeps;		# searchpath plus aggregate deps plus kiwi deps
			# maps prp => [ prp, prp ... ]
			# used for sorting
#my %prpnoleaf;		# is this prp referenced by another prp?
#my @projpacks_linked;	# data of all linked sources

my %_repounchanged;
my %_prpfinished;
my %_prpnotready;	# maps prp => { packid => 1, ... }

my $_maxserverload = 1;
$_maxserverload = $BSConfig::sched_maxserverload if $BSConfig::sched_maxserverload;


##########################################################################
##########################################################################

sub select_read {
  my ($timeout, @watchers) = @_;
  my @retrywatchers = grep {$_->{'retry'}} @watchers;
  if (@retrywatchers) {
    my $now = time();
    for (splice @retrywatchers) {
      if ($_->{'retry'} <= $now) {
        push @retrywatchers, $_;
	next;
      }
      $timeout = $_->{'retry'} - $now if !defined($timeout) || $_->{'retry'} - $now < $timeout;
    }
    return @retrywatchers if @retrywatchers;
    @watchers = grep {!$_->{'retry'}} @watchers;
  }
  @watchers = grep {exists $_->{'socket'}} @watchers;
  while(1) {
    my $rin = '';
    for (@watchers) {
      vec($rin, fileno($_->{'socket'}), 1) = 1;
    }
    my $nfound = select($rin, undef, undef, $timeout);
    if (!defined($nfound) || $nfound == -1) {
      next if $! == POSIX::EINTR;
      die("select: $!\n");
    }
    return () if !$nfound && defined($timeout);
    die("select: $!\n") unless $nfound;
    @watchers = grep {vec($rin, fileno($_->{'socket'}), 1)} @watchers;
    die unless @watchers;
    return @watchers;
  }
}


sub writeschedulerinfo {
  my ($gctx) = @_;

  my $myarch = $gctx->{'arch'};
  my $projpacks = $gctx->{'projpacks'};
  my $prpunfinished = $gctx->{'prpunfinished'};
  my $prpchecktimes = $gctx->{'prpchecktimes'};

  # update scheduler stats
  my $sinfo = {'arch' => $myarch, 'started' => $gctx->{'schedulerstart'}, 'time' => time(), 'slept' => $gctx->{'slept'}};
  $sinfo->{'projects'} = keys %$projpacks;
  $sinfo->{'repositories'} = @{$gctx->{'prps'} || []};
  my $unfinishedsum = 0;
  $unfinishedsum += $_ for values %{$prpunfinished || {}};
  $sinfo->{'notready'} = $unfinishedsum;
  $sinfo->{'queue'} = {};
  $sinfo->{'queue'}->{'high'} = @{$gctx->{'lookat_high'}};
  $sinfo->{'queue'}->{'med'} = @{$gctx->{'lookat_med'}};
  $sinfo->{'queue'}->{'low'} = @{$gctx->{'lookat_low'}};
  $sinfo->{'queue'}->{'next'} = keys %{$gctx->{'lookat_next'}};
  my $sum = 0;
  my $sum2 = 0;
  my $n = keys %$prpchecktimes;
  for my $prp (sort keys %$prpchecktimes) {
    my $t = $prpchecktimes->{$prp};
    $sum += $t;
    $sum2 += $t * $t;
  }
  $sinfo->{'avg'} = $sum / $n;
  $sinfo->{'variance'} = sqrt(abs(($sum2 - $sum * $sum / $n) / $n));
  for my $prp (splice(@{[sort {$prpchecktimes->{$b} <=> $prpchecktimes->{$a}} keys %$prpchecktimes]}, 0, 10)) {
    my ($projid, $repoid) = split('/', $prp, 2);
    my $worst = {'project' => $projid, 'repository' => $repoid};
    $worst->{'packages'} = keys %{($projpacks->{$projid} || {})->{'package'} || {}};
    $worst->{'time'} = $prpchecktimes->{$prp};
    push @{$sinfo->{'worst'}}, $worst;
  }
  $sinfo->{'buildavg'} = $gctx->{'buildavg'};
  writexml("$infodir/.schedulerinfo.$myarch", "$infodir/schedulerinfo.$myarch", $sinfo, $BSXML::schedulerinfo);
}


sub updaterelsyncmax {
  my ($gctx, $prp, $arch, $new, $cleanup) = @_;
  my $reporoot = $gctx->{'reporoot'};
  local *F;
  BSUtil::lockopen(\*F, '+>>', "$reporoot/$prp/$arch/:relsync.max");
  my $relsyncmax;
  if (-s "$reporoot/$prp/$arch/:relsync.max") {
    $relsyncmax = BSUtil::retrieve("$reporoot/$prp/$arch/:relsync.max", 2);
  }
  $relsyncmax ||= {};
  my $changed;
  for my $tag (keys %$new) {
    next if defined($relsyncmax->{$tag}) && $relsyncmax->{$tag} >= $new->{$tag};   
    $relsyncmax->{$tag} = $new->{$tag};
    $changed = 1;
  }
  if ($cleanup) {
    for (grep {!$new->{$_}} keys %$relsyncmax) {
      delete $relsyncmax->{$_};
      $changed = 1;
    }
  }
  BSUtil::store("$reporoot/$prp/$arch/.:relsync.max", "$reporoot/$prp/$arch/:relsync.max", $relsyncmax) if $changed;
  close(F);
  return $changed;
}

sub sendrelsyncupdate {
  my ($gctx, $prp, $isfinished) = @_;

  print "    updating relsync information\n";
  my $myarch = $gctx->{'myarch'};
  my $reporoot = $gctx->{'reporoot'};

  my ($projid, $repoid) = split('/', $prp, 2);
  my $projpacks = $gctx->{'projpacks'};
  my $packs = ($projpacks->{$projid} || {})->{'package'} || {};
  my $relsync = BSUtil::retrieve("$reporoot/$prp/$myarch/:relsync") || {};
  my $relsyncmax = {};
  for my $packid (sort keys %$relsync) {
    next unless $relsync->{$packid} =~ /^(.*)\.([^-]*)$/;
    my $tag = ($packs->{$packid} || {})->{'bcntsynctag'} || $packid;
    next if defined($relsyncmax->{"$tag/$1"}) && $relsyncmax->{"$tag/$1"} >= $2;
    $relsyncmax->{"$tag/$1"} = $2;
  }
  updaterelsyncmax($gctx, $prp, $myarch, $relsyncmax, $isfinished);
  # sent new data!
  my $param = {
    'uri' => "$BSConfig::srcserver/relsync",
    'request' => 'POST',
    'data' => BSUtil::tostorable($relsyncmax),
  };
  eval {
    BSRPC::rpc($param, undef, "project=$projid", "repository=$repoid", "arch=$myarch");
  };
  if (!$@) {
    unlink("$reporoot/$prp/$myarch/:relsync$$");
    link("$reporoot/$prp/$myarch/:relsync", "$reporoot/$prp/$myarch/:relsync$$");
    rename("$reporoot/$prp/$myarch/:relsync$$", "$reporoot/$prp/$myarch/:relsync.sent");
  } else {
    warn($@);
  }
}

sub mergerelsyncfile {
  my ($gctx, $prp) = @_;

  print "    merging relsync data\n";
  my $myarch = $gctx->{'myarch'};
  my $reporoot = $gctx->{'reporoot'};
  my $relsync_merge = BSUtil::retrieve("$reporoot/$prp/$myarch/:relsync.merge", 2);
  if ($relsync_merge) {
    my $relsync;
    $relsync = BSUtil::retrieve("$reporoot/$prp/$myarch/:relsync", 2) if -e "$reporoot/$prp/$myarch/:relsync";
    $relsync = { %{$relsync || {}}, %$relsync_merge };
    BSUtil::store("$reporoot/$prp/$myarch/.:relsync", "$reporoot/$prp/$myarch/:relsync", $relsync);
  }
  unlink("$reporoot/$prp/$myarch/:relsync.merge");
}

sub mergemetacachefile {
  my ($gctx, $prp) = @_;

  print "    merging metacache data\n";
  my $myarch = $gctx->{'myarch'};
  my $reporoot = $gctx->{'reporoot'};
  my $metacache_merge = BSUtil::retrieve("$reporoot/$prp/$myarch/:full.metacache.merge", 2);
  if ($metacache_merge) {
    my $metacache;
    $metacache = BSUtil::retrieve("$reporoot/$prp/$myarch/:full.metacache", 2) if -e "$reporoot/$prp/$myarch/:full.metacache";
    $metacache = { %{$metacache || {}}, %$metacache_merge };
    delete $metacache->{$_} for grep {!defined($metacache_merge->{$_})} keys %$metacache_merge;
    if (%$metacache) {
      BSUtil::store("$reporoot/$prp/$myarch/.:full.metacache", "$reporoot/$prp/$myarch/:full.metacache", $metacache);
    } else {
      unlink("$reporoot/$prp/$myarch/:full.metacache");
    }
  }
  unlink("$reporoot/$prp/$myarch/:full.metacache.merge");
}

sub mergebininfofile {
  my ($gctx, $prp) = @_;

  my $myarch = $gctx->{'myarch'};
  my $reporoot = $gctx->{'reporoot'};
  BSSched::BuildResult::read_gbininfo("$reporoot/$prp/$myarch");
  my $repounchanged = $gctx->{'repounchanged'};
  $repounchanged->{$prp} = 2 if $repounchanged->{$prp};
}

my %handlers = (
  'kiwi-product'    => BSSched::BuildJob::KiwiProduct->new(),
  'kiwi-image'      => BSSched::BuildJob::KiwiImage->new(),
  'patchinfo'       => BSSched::BuildJob::Patchinfo->new(),
  'aggregate'       => BSSched::BuildJob::Aggregate->new(),
  'preinstallimage' => BSSched::BuildJob::PreInstallImage->new(),
  'simpleimage'     => BSSched::BuildJob::SimpleImage->new(),
  'channel'         => BSSched::BuildJob::Channel->new(),
  'unknown'         => BSSched::BuildJob::Unknown->new(),
);

my $defaulthandler = BSSched::BuildJob::Package->new();


##########################################################################
##########################################################################
##
## Scheduler startup code
##

$| = 1;
$SIG{'PIPE'} = 'IGNORE';
if ($testmode && ($testmode eq 'exit' || $testmode eq 'restart')) {
  if (!(-e "$_rundir/bs_sched.$_myarch.lock") || BSUtil::lockcheck('>>', "$_rundir/bs_sched.$_myarch.lock")) {
    die("scheduler is not running for $_myarch.\n") if $testmode eq 'restart';
    print("scheduler is not running for $_myarch.\n");
    exit(0);
  }
  if ($testmode eq 'restart') {
    print "restarting scheduler for $_myarch...\n";
  } else {
    print "shutting down scheduler for $_myarch...\n";
  }
  my $ev = {
    'type' => $testmode eq 'restart' ? 'restart' : 'exitcomplete',
  };
  my $evname = "$ev->{'type'}::";
  my $gctx = {'eventdir' => $_eventdir};
  BSSched::Events::sendevent($gctx, $ev, $_myarch, $evname);
  BSUtil::waituntilgone("$_eventdir/$_myarch/$evname");
  if ($testmode eq 'exit') {
    # scheduler saw the event, wait until the process is gone
    local *F;
    BSUtil::lockopen(\*F, '>>', "$_rundir/bs_sched.$_myarch.lock", 1);
    close F;
  }
  exit(0);
}
print "starting build service scheduler\n";

# get lock
mkdir_p($_rundir);
if (!$testprojid) {
  open(RUNLOCK, '>>', "$_rundir/bs_sched.$_myarch.lock") || die("$_rundir/bs_sched.$_myarch.lock: $!\n");
  flock(RUNLOCK, LOCK_EX | LOCK_NB) || die("scheduler is already running for $_myarch!\n");
  utime undef, undef, "$_rundir/bs_sched.$_myarch.lock";
}

for my $d ("$_eventdir/$_myarch", "$_jobsdir/$_myarch", $infodir) {
  next if -d $d;
  mkdir_p($d) || die("$d: $!\n");
}
# setup event mechanism
my $_myeventdir = "$_eventdir/$_myarch";
if (!-p "$_myeventdir/.ping") {
  POSIX::mkfifo("$_myeventdir/.ping", 0666) || die("$_myeventdir/.ping: $!");
  chmod(0666, "$_myeventdir/.ping");
}

sysopen(PING, "$_myeventdir/.ping", POSIX::O_RDWR) || die("$_myeventdir/.ping: $!");
fcntl(PING, F_SETFL, POSIX::O_NONBLOCK);


# changed: 1: something "local" changed, :full unchanged,
#          2: the :full repo is changed
# set all projects and prps to :full repo changed
my %changed_low;
my %changed_med;
my %changed_high;
my %changed_dirty;
my %lastcheck;
my %delayedfetchprojpacks;

my %lookat_next;	# not so important, next series
my @lookat_low;         # not so important
my @lookat_med;         # do those first (out of band), triggered through direct build results
my @lookat_high;        # do those really first so that our users are happy, triggered through user interaction

# create global context
my $gctx = {
  'arch' => $_myarch,
  'reporoot' => $_reporoot,

  # config
  'obsname' => $BSConfig::obsname,
  'jobsdir' => $_jobsdir,
  'myjobsdir' => "$_jobsdir/$_myarch",
  'eventdir' => $_eventdir,
  'myeventdir' => $_myeventdir,
  'extrepodir' => $_extrepodir,
  'dodsdir' => $_dodsdir,
  'rundir' => $_rundir,
  'remotecache' => $_remotecache,
  'remoteproxy' => $BSConfig::proxy,
  'asyncmode' => $asyncmode,

  # repository state cache
  'repodatas' => \%_repodatas,
  'repodatas_alien' => \%_repodatas_alien,

  # remote bininfo cache
  'remotegbininfos' => \%_remotegbininfos,
  'remotepackstatus' => \%_remotepackstatus,
  'remotepackstatus_cleanup' => \%_remotepackstatus_cleanup,

  # project data
  'projpacks' => undef,
  'channeldata' => \%_channeldata,
  'remoteprojs' => \%_remoteprojs,

  # postprocessed project data
  'projpacks_linked' => [],
  'prps' => [],
  'prpdeps' => {},
  'prpnoleaf' => {},
  'prpsearchpath' => {},

  # triggers
  'prpcheckuseforbuild' => \%_prpcheckuseforbuild,
  'prpfinished' => \%_prpfinished,
  'repounchanged' => \%_repounchanged,
  'prpnotready' => \%_prpnotready,

  # remote watchers
  'watchremote' => {},			# remote_url => { eventdescr => projid }
  'watchremote_start' => {},		# remote_url => lasteventno

  'changed_low' => \%changed_low,
  'changed_med' => \%changed_med,
  'changed_high' => \%changed_high,
  'changed_dirty' => \%changed_dirty,

  'lookat_low' => \@lookat_low,
  'lookat_med' => \@lookat_med,
  'lookat_high' => \@lookat_high,
  'lookat_next' => \%lookat_next,
  'notlow'	=> 0,
  'notmed'	=> 0,

  'delayedfetchprojpacks' => \%delayedfetchprojpacks,

  'nextmed' => {},
  'retryevents' => [],

  # stats
  'buildavg' => 1200,			 # start not at 0, but with 20min for the average ounter
  'prpunfinished' => {},
  'prpchecktimes' => {},
  'schedulerstart' => time(),
  'slept' => 0,
  'prplastcheck' => {},			# XXX: currently not used
};

my $rctx = BSSched::RPC->new(
  'maxserverload' => $_maxserverload,
  'wakeupfunction' => \&BSSched::Lookat::setchanged,
);

$gctx->{'rctx'} = $rctx;

$gctx->{'testmode'} = 1 if $testmode;
$BSSched::ProjPacks::testprojid = $testprojid if $testprojid;

# read old state if present
if (!$testprojid && -s "$_rundir/bs_sched.$_myarch.state") {
  print "reading old state...\n";
  my $schedstate = BSUtil::retrieve("$_rundir/bs_sched.$_myarch.state", 2);
  unlink("$_rundir/bs_sched.$_myarch.state");
  if ($schedstate) {
    # just for testing...
    print "  - $_\n" for sort keys %$schedstate;
    if ($schedstate->{'projpacks'}) {
      $gctx->{'projpacks'} = $schedstate->{'projpacks'};
      if ($schedstate->{'remoteprojs'}) {
	$gctx->{'remoteprojs'} = $schedstate->{'remoteprojs'};
	for (values %{$gctx->{'remoteprojs'}}) {
	  next unless $_->{'sibling'};
	  $_->{'partition'} ||= $_->{'sibling'};
	  delete $_->{'sibling'};
	}
      }
    } else {
      # get project and package information from src server
      BSSched::ProjPacks::get_projpacks($gctx, undef);	# XXX: async
    }
    BSSched::ProjPacks::get_projpacks_postprocess($gctx);
    my $projpacks = $gctx->{'projpacks'};
    my $prps = $gctx->{'prps'};

    my %oldprps = map {$_ => 1} @{$schedstate->{'prps'} || []};
    my @newprps = grep {!$oldprps{$_}} @$prps;

    # update lookat arrays
    @lookat_low = @{$schedstate->{'lookat'} || []};
    @lookat_med = @{$schedstate->{'lookat_oob'} || []};
    @lookat_high = @{$schedstate->{'lookat_oobhigh'} || []};

    # update changed hash
    %changed_low = ();
    %changed_med = ();
    %changed_high = ();
    for my $prp (@newprps) {
      $changed_med{$prp} = 2;
      $changed_med{(split('/', $prp, 2))[0]} = 2;
    }

    my $oldchanged_low = $schedstate->{'changed_low'} || {};
    my $oldchanged_med = $schedstate->{'changed_med'} || {};
    my $oldchanged_high = $schedstate->{'changed_high'} || {};
    for my $projid (keys %$projpacks) {
      $changed_low{$projid} = $oldchanged_low->{$projid} if exists $oldchanged_low->{$projid};
      $changed_med{$projid} = $oldchanged_med->{$projid} if exists $oldchanged_med->{$projid};
      $changed_high{$projid} = $oldchanged_high->{$projid} if exists $oldchanged_high->{$projid};
    }
    for my $prp (@$prps) {
      $changed_low{$prp} = $oldchanged_low->{$prp} if exists $oldchanged_low->{$prp};
      $changed_med{$prp} = $oldchanged_med->{$prp} if exists $oldchanged_med->{$prp};
      $changed_high{$prp} = $oldchanged_high->{$prp} if exists $oldchanged_high->{$prp};
    }

    ## update repodata hash
    #my $oldrepodata = $schedstate->{'repodata'} || {};
    #for my $prp (@$prps) {
    #  $repodata{$prp} = $oldrepodata->{$prp} if exists $oldrepodata->{$prp};
    #}

    # update prpfinished hash
    my $oldprpfinished = $schedstate->{'prpfinished'} || {};
    my $prpfinished = $gctx->{'prpfinished'};
    for my $prp (@$prps) {
      $prpfinished->{$prp} = $oldprpfinished->{$prp} if exists $oldprpfinished->{$prp};
    }

    # update prpnotready hash
    my $oldprpnotready = $schedstate->{'globalnotready'} || {};
    my $prpnotready = $gctx->{'prpnotready'};
    for my $prp (@$prps) {
      $prpnotready->{$prp} = $oldprpnotready->{$prp} if %{$oldprpnotready->{$prp} || {}};
    }

    # update repounchanged hash
    my $oldrepounchanged = $schedstate->{'repounchanged'} || {};
    my $repounchanged = $gctx->{'repounchanged'};
    for my $prp (@$prps) {
      $repounchanged->{$prp} = $oldrepounchanged->{$prp} if exists $oldrepounchanged->{$prp};
    }

    # update delayedfetchprojpacks hash
    my $olddelayedfetchprojpacks = $schedstate->{'delayedfetchprojpacks'} || {};
    for my $projid (keys %$projpacks) {
      $delayedfetchprojpacks{$projid} = $olddelayedfetchprojpacks->{$projid} if $olddelayedfetchprojpacks->{$projid};
    }

    # use old start values
    if ($schedstate->{'watchremote_start'}) {
      $gctx->{'watchremote_start'} = $schedstate->{'watchremote_start'};
    }

    # start project data fetch for delayed startup projects
    for my $projid (sort keys %$projpacks) {
      my $packs = $projpacks->{$projid}->{'package'} || {};
      for my $packid (sort keys %$packs) {
        $delayedfetchprojpacks{$projid} = [ '/all' ] if ($packs->{$packid}->{'error'} || '') eq 'delayed startup';
      }
    }

    if ($schedstate->{'fetchprojpacks'} && $schedstate->{'projpacks'}) {
      my %fetchprojpacks_nodelay = map {$_ => 1} keys %{$schedstate->{'fetchprojpacks'}};
      BSSched::ProjPacks::do_fetchprojpacks($gctx, $asyncmode, $schedstate->{'fetchprojpacks'}, \%fetchprojpacks_nodelay, {}, {});
    }
  }
}

if (!$gctx->{'projpacks'} && $startupmode) {
  if ($startupmode == 1) {
    print "cold start, scanning all non-remote projects\n";
  } else {
    print "cold start, initializing all projects\n";
  }
  my $param = {
    'uri' => "$BSConfig::srcserver/getprojpack",
  };
  my @args = ('withrepos', 'withconfig', "arch=$_myarch", 'withremotemap=1', 'noremote=1');
  push @args, 'withsrcmd5', 'withdeps' if $startupmode == 1;
  push @args, "partition=$BSConfig::partition" if $BSConfig::partition;
  my $projpacksin;
  while (1) {
    eval {
      $projpacksin = BSRPC::rpc($param, $BSXML::projpack, @args);
    };
    last unless $@ || !$projpacksin;
    print $@ if $@;
    print "retrying in 60 seconds...\n";
    sleep(60);
  }
  BSSched::ProjPacks::update_projpacks($gctx, $projpacksin);
  BSSched::ProjPacks::get_projpacks_postprocess($gctx);
  my $projpacks = $gctx->{'projpacks'};
  for my $projid (sort keys %$projpacks) {
    my $packs = $projpacks->{$projid}->{'package'} || {};
    next unless %$packs;
    if ($startupmode == 1) {
      my @delayed;
      my $ok;
      for my $packid (sort keys %$packs) {
	my $pdata = $packs->{$packid};
	if ($pdata->{'error'}) {
	  if ($pdata->{'error'} =~ /noremote option/) {
	    $pdata->{'error'} = 'delayed startup';
	    push @delayed, $packid;
	  } else {
	    $ok++;
	  }
	} else {
	  if (grep {$_->{'error'} && $_->{'error'} =~ /noremote option/} @{$pdata->{'info'} || []}) {
	    $pdata->{'error'} = 'delayed startup';
	    push @delayed, $packid;
	  } else {
	    $ok++;
	  }
	}
      }
      if (!$ok) {
        $delayedfetchprojpacks{$projid} = [ '/all' ];	# hack
      } else {
        $delayedfetchprojpacks{$projid} = [ @delayed ];
      }
    } else {
      $delayedfetchprojpacks{$projid} = [ '/all' ];	# hack
      for my $packid (sort keys %$packs) {
        $packs->{$packid}->{'error'} = 'delayed startup';
      }
    }
  }
  @lookat_low = sort keys %$projpacks;
  push @lookat_low, @{$gctx->{'prps'}};
  my $prpcheckuseforbuild = $gctx->{'prpcheckuseforbuild'};
  $prpcheckuseforbuild->{$_} = 1 for @{$gctx->{'prps'}};
}

if (!$gctx->{'projpacks'}) {
  # get project and package information from src server
  print "cold start, scanning all projects\n";
  BSSched::ProjPacks::get_projpacks($gctx, undef);
  BSSched::ProjPacks::get_projpacks($gctx, undef, 'opensuse_org') if $testprojid;
  BSSched::ProjPacks::get_projpacks_postprocess($gctx);
  # look at everything
  @lookat_low = sort keys %{$gctx->{'projpacks'}};
  push @lookat_low, @{$gctx->{'prps'}};
}

# bring dods in sync with projpacks
if ($BSConfig::enable_download_on_demand) {
  BSSched::DoD::init_doddata($gctx);
} else {
  my $dodsdir = $gctx->{'dodsdir'};
  BSUtil::cleandir($dodsdir) if -d $dodsdir;
}

BSSched::BuildJob::init_ourjobs($gctx);

unlink("$_rundir/bs_sched.$_myarch.dead");	# alive and kicking

#XXX
#@lookat_low = sort keys %$projpacks;
#push @lookat_low, @prps;

my %remotewatchers;

if (@lookat_low) {
  %lookat_next = map {$_ => 1} @lookat_low;
  @lookat_low = ();
}

my $gotevent = 1;
$gotevent = 0 if $testprojid;

my $lastschedinfo = 0;
my $initialstartup = 1;


##
## Here comes the big loop...
##

my $reporoot = $gctx->{'reporoot'};
my $myarch = $gctx->{'arch'};

eval {

  while(1) {
NEXTPRP:
    if (%changed_low || %changed_med || %changed_high) {
      BSSched::Lookat::changed2lookat($gctx);
      next;
    }

    my $watchremote = $gctx->{'watchremote'};
    my $watchremote_start = $gctx->{'watchremote_start'};

    # delete no longer needed or outdated remotewatchers
    for my $remoteurl (sort keys %remotewatchers) {
      my $watcher = $remotewatchers{$remoteurl};
      if (!$watchremote->{$remoteurl} || join("\0", sort keys %{$watchremote->{$remoteurl}}) ne $watcher->{'watchlist'}) {
	close $watcher->{'socket'} if defined $watcher->{'socket'};
	delete $remotewatchers{$remoteurl};
	next;
      }
    }

    # create watchers
    for my $remoteurl (sort keys %$watchremote) {
      if (!$remotewatchers{$remoteurl}) {
	my $watcher = BSSched::Remote::setupremotewatcher($gctx, $remoteurl, $watchremote->{$remoteurl}, $watchremote_start->{$remoteurl});
	$watcher->{'watchlist'} = join("\0", sort keys %{$watchremote->{$remoteurl}});
	$remotewatchers{$remoteurl} = $watcher;
      }
    }

    # collect events to process
    my @events;

    my $pingwatcher = {
      'socket' => \*PING,
      'remoteurl' => 'ping',
    };

    # add retry events
    if (@{$gctx->{'retryevents'}}) {
      my @due = BSSched::Remote::getretryevents($gctx);
      if (@due) {
	print "retrying ".@due." events\n";
	push @events, @due;
      }
    }

    # add events from watchers, also process finished xrpc calls
    if ($testprojid) {
      print "ignoring events due to test mode\n";
    } else {
      my @watchers = (values(%remotewatchers), $gctx->{'rctx'}->xrpc_handles());
      if (@watchers) {
        @watchers = select_read(0, $pingwatcher, @watchers);
	for my $watcher (@watchers) {
	  my $remoteurl = $watcher->{'remoteurl'};
	  if (!defined($remoteurl)) {
	    $gctx->{'rctx'}->xrpc_resume($watcher);
	  } elsif ($remoteurl eq 'ping') {
            $gotevent = 1;
	  } elsif ($watcher->{'retry'}) {
	    print "retrying watcher for $remoteurl\n";
	    delete $remotewatchers{$remoteurl};
	  } else {
	    push @events, BSSched::Remote::getremoteevents($gctx, $watcher, $watchremote->{$remoteurl}, $watchremote_start);
	    delete $remotewatchers{$remoteurl} unless $watcher->{'retry'};
	  }
	}
      } else {
	my $dummy;
        $gotevent = 1 if (sysread(PING, $dummy, 1, 0) || 0) > 0;
      }
    }

    # add events from the event directory
    if ($gotevent) {
      $gotevent = 0;
      # drain ping pipe
      my $dummy;
      1 while (sysread(PING, $dummy, 1024, 0) || 0) > 0;
      # add events from myeventdir
      push @events, BSSched::Events::readevents($gctx, $gctx->{'myeventdir'});
    }

    # process all collected events
    if (@events) {
      die if $testprojid;

      # create event processor
      my $ectx = BSSched::Events->new(
	'gctx' => $gctx,
	'initialstartup' => $initialstartup,
      );
      eval {
        @events = $ectx->order(@events);
	if ($ectx->process_events(@events)) {
	  # could not process all events, re-run
	  $gotevent = 1;
	}
      };
      if ($@) {
        warn($@);
        BSSched::Events::event_exit($ectx, {'type' => 'emergencydump'});
        exit(1);
      }
      next;
    }

    # done with first time event processing
    $initialstartup = undef;

    # mark all indirect affected repos dirty
    for my $prp (keys %changed_dirty) {
      my $reporoot = $gctx->{'reporoot'};
      next if ! -d "$reporoot/$prp/$myarch";
      next if   -e "$reporoot/$prp/$myarch/:schedulerstate.dirty";
      BSUtil::touch("$reporoot/$prp/$myarch/:schedulerstate.dirty");
    }
    %changed_dirty = ();

    my ($lookattype, $prp) = BSSched::Lookat::nextlookat($gctx);

    # postpone if we got source change RPCs running
    if (defined($prp)) {
      my ($projid) = split('/', $prp, 2);
      if ($gctx->{'rctx'}->xrpc_busy($projid)) {
	my $ctx = {'changeprp' => $prp, 'changetype' => $lookattype, 'gctx' => $gctx};
	$gctx->{'rctx'}->xrpc_addwakeup($ctx, $projid);
	next;
      }
    }

    $gctx->{'rctx'}->xrpc_printstats();

    if (!defined($prp)) {
      # nothing to do. good night, sleep tight...
      if ($testmode && !$gctx->{'rctx'}->xrpc_busy()) {
	print "Test mode, all sources and events processed, exiting...\n";
        BSSched::Events::event_exit({ 'gctx' => $gctx }, { 'type' => 'exitcomplete' });
      }
      my @ltim = localtime(time);
      my $msgtm = sprintf "%04d-%02d-%02d %02d:%02d:%02d:", $ltim[5] + 1900, $ltim[4] + 1, @ltim[3,2,1,0];
      print "$msgtm waiting for an event...\n";
      exit 0 if $testprojid;
      my $sleepstart = time();
      my @watchers = (values(%remotewatchers), @{$gctx->{'retryevents'}}, $gctx->{'rctx'}->xrpc_handles());
      select_read(undef, $pingwatcher, @watchers);
      $gctx->{'slept'} += time() - $sleepstart;
      next;
    }

    BSSched::Lookat::lookatprp($gctx, $lookattype, $prp);

    my ($projid, $repoid) = split('/', $prp, 2);
    next if $testprojid && $projid ne $testprojid;

    if (!defined($repoid)) {
      # project maintenance, check for deleted repositories
      my $projpacks = $gctx->{'projpacks'};
      my %repoids;
      for my $repo (@{($projpacks->{$projid} || {})->{'repository'} || []}) {
	$repoids{$repo->{'name'}} = 1 if grep {$_ eq $myarch} @{$repo->{'arch'} || []};
      }
      for my $repoid (ls("$reporoot/$projid")) {
	next if $repoid eq ':all';	# XXX
	next if $repoids{$repoid};
	my $prp = "$projid/$repoid";
	next if -l "$reporoot/$prp";	# XXX
	my $gdst = "$reporoot/$prp/$myarch";
	next unless -d $gdst;
	# we no longer build this repoid
	print "  - deleting repository $prp\n";
	delete $gctx->{'prpfinished'}->{$prp};
	delete $gctx->{'prpnotready'}->{$prp};
	delete $gctx->{'prpunfinished'}->{$prp};
	delete $gctx->{'prpchecktimes'}->{$prp};
	delete $gctx->{'repodatas'}->{$prp};
	delete $lastcheck{$prp};
	delete $gctx->{'prpcheckuseforbuild'}->{$prp};
	for my $dir (ls($gdst)) {
	  # need lock for deleting publish area
	  next if $dir eq ':repo' || $dir eq ':repoinfo';
	  if (-d "$gdst/$dir") {
	    BSUtil::cleandir("$gdst/$dir");
	    rmdir("$gdst/$dir") || die("$gdst/$dir: $!\n");
	  } else {
	    unlink("$gdst/$dir") || die("$gdst/$dir: $!\n");
	  }
	}
	$changed_med{$prp} = 2;
	BSSched::Events::sendrepochangeevent($gctx, $prp);
	BSSched::BuildJob::killbuilding($gctx, $prp);
	my $ctx = {'gctx' => $gctx, 'prp' => $prp, 'gdst' => $gdst };
	BSSched::PublishRepo::prpfinished($ctx);
	# now that :repo is gone we can remove the directory
	while (!rmdir($gdst)) {
	  die("$gdst: $!\n") unless -e "$gdst/:schedulerstate.dirty";
	  print "rep server created dirty file $gdst/:schedulerstate.dirty, retry ...\n";
	  unlink("$gdst/:schedulerstate.dirty");
	}
	# XXX this should be rewritten if :repoinfo lives somewhere else
	my $repo = (grep {$_->{'name'} eq $repoid} @{($projpacks->{$projid} || {})->{'repository'} || []})[0];
	if (!$repo) {
	  # this repo doesn't exist any longer!
	  my $others;
	  for (ls("$reporoot/$prp")) {
	    next unless -d $_;
	    $others = 1;
	  }
	  if (!$others) {
	    # cannot delete repoinfo because it maz contain splitdbg data
	    # unlink("$reporoot/$prp/:repoinfo");
	    unlink("$reporoot/$prp/.finishedlock");
	    rmdir("$reporoot/$prp");
	  }
	}
      }
      rmdir("$reporoot/$projid");		# in case this was the last repo
      next;
    }

    # do delayed projpack fetches
    while ($delayedfetchprojpacks{$projid}) {
      my $async;
      $async = {'_changeprp' => $prp, '_changetype' => $lookattype} if $asyncmode;
      my $delayed = delete $delayedfetchprojpacks{$projid};
      if ($delayed) {
	if (!BSSched::ProjPacks::do_delayedprojpackfetches($gctx, $async, $projid, @$delayed)) {
	  # async request in progress...
          goto NEXTPRP;
	}
      }
    }

    my $projpacks = $gctx->{'projpacks'};
    my $prpsearchpath = $gctx->{'prpsearchpath'}->{$prp};

    if (!$projpacks->{$projid} || !$prpsearchpath) {
      next if $gctx->{'remoteprojs'}->{$projid};
      print "  - $prp: no longer exists\n";
      next;
    }

    # merge bininfo
    if (-e "$reporoot/$prp/$myarch/:bininfo.merge" || ! -e "$reporoot/$prp/$myarch/:bininfo") {
      mergebininfofile($gctx, $prp);
    }

    # merge relsync
    if (-e "$reporoot/$prp/$myarch/:relsync.merge") {
      mergerelsyncfile($gctx, $prp);
    }

    # merge metacache
    if (-e "$reporoot/$prp/$myarch/:full.metacache.merge") {
      mergemetacachefile($gctx, $prp);
    }

    my $bconf = BSSched::ProjPacks::getconfig($gctx, $myarch, $prpsearchpath);
    if (!$bconf) {
      # see if it is caused by a remote error
      my $error;
      my $remoteprojs = $gctx->{'remoteprojs'};
      for my $pprp (@$prpsearchpath) {
	my ($pprojid, $prepoid) = split('/', $pprp, 2);
	$error = $remoteprojs->{$pprojid}->{'error'} if $remoteprojs->{$pprojid} && $remoteprojs->{$pprojid}->{'error'};
	if ($error) {
	  if ($error =~ /interconnect error:/) {
	    BSSched::Remote::addretryevent($gctx, {'type' => 'project', 'project' => $pprojid});
	  }
	  print "  - $prp: $pprojid: $error\n";
	  last;
	}
      }
      next if $error;
      my $lastprojid = (split('/', $prpsearchpath->[-1]))[0];
      print "  - $prp: no config ($lastprojid)\n";
      set_repo_state($gctx, $prp, 'broken', "no config ($lastprojid)");
      $gctx->{'prpfinished'}->{$prp} = 1;
      next;
    }

    my $prptype = $bconf->{'type'};
    if (!$prptype || $prptype eq 'UNDEFINED') {
      # HACK force to channel if we have a channel package
      $prptype = 'channel' if grep {$_->{'channel'}} values(%{$projpacks->{$projid}->{'package'} || {}});
    }
    if (!$prptype || $prptype eq 'UNDEFINED') {
      # could still do channels/aggregates/patchinfos
      my $lastprojid = (split('/', $prpsearchpath->[-1]))[0];
      print "  - $prp: bad config ($lastprojid)\n";
      set_repo_state($gctx, $prp, 'broken', "bad config ($lastprojid)");
      $gctx->{'prpfinished'}->{$prp} = 1;
      next;
    }
    if ($bconf->{'hostarch'} && !$BSCando::knownarch{$bconf->{'hostarch'}}) {
      print "  - $prp: bad hostarch ($bconf->{'hostarch'})\n";
      set_repo_state($gctx, $prp, 'broken', "bad hostarch ($bconf->{'hostarch'})");
      $gctx->{'prpfinished'}->{$prp} = 1;
      next;
    }
    my $repo = (grep {$_->{'name'} eq $repoid} @{$projpacks->{$projid}->{'repository'} || []})[0];
    if (!$repo) {
      print " - $prp: no repo?\n";
      set_repo_state($gctx, $prp, 'broken', 'no repo');
      $gctx->{'prpfinished'}->{$prp} = 1;
      next;
    }

    print "  - $prp\n";

    if ($gctx->{'prpcheckuseforbuild'}->{$prp}) {
      my $packs = $projpacks->{$projid}->{'package'} || {};
      # the if statement below is to ease transition to the new full handling
      # for manually created "base" repos
      if (!$BSSched::BuildResult::new_full_handling || %$packs || ! -d "$reporoot/$prp/$myarch/:full" ||
          -e "$reporoot/$prp/$myarch/:full.useforbuild") {
        BSSched::BuildRepo::checkuseforbuild($gctx, $prp, $prpsearchpath, undef);
        delete $gctx->{'prpcheckuseforbuild'}->{$prp};
      }
    }
    if (!$lastcheck{$prp}) {
      my $oldlastcheck = BSUtil::retrieve("$reporoot/$prp/$myarch/:lastcheck", 1) || {};
      my $packs = $projpacks->{$projid}->{'package'} || {};
      for (keys %$oldlastcheck) {
	# delete old cruft
	delete $oldlastcheck->{$_} unless $packs->{$_};
      }
      $lastcheck{$prp} = $oldlastcheck;
    }

    # create check context
    my $ctx = { 'project' => $projid, 'repository' => $repoid, 'prp' => $prp,
		'repo' => $repo, 'gctx' => $gctx,
		'changetype' => $lookattype, 'changeprp' => $prp, 
		'prpsearchpath' => $prpsearchpath || [], 'conf' => $bconf,
		'lastcheck' => $lastcheck{$prp}, 'gdst' => "$gctx->{'reporoot'}/$prp/$myarch"};

    if ($repo->{'status'} && $repo->{'status'} eq 'disabled') {
      print "      disabled\n";
      set_repo_state($gctx, $prp, 'disabled');
      $gctx->{'prpfinished'}->{$prp} = 1;
      next;
    }

    mkdir_p("$reporoot/$prp/$myarch");
    set_repo_state($gctx, $prp, 'scheduling');

    my $packs = $projpacks->{$projid}->{'package'} || {};
    my @packs = sort keys %$packs;

    # XXX: setup packid2info hash?

    # Step 2a: check if packages got deleted/excluded
    for my $packid (grep {!/^[:\.]/} ls("$reporoot/$prp/$myarch")) {
      next if $packid eq '_volatile';
      my $reason;
      if (!$packs->{$packid}) {
	next if $packid eq '_deltas';
	next if $projpacks->{$projid}->{'missingpackages'};
	$reason = 'obsolete';
      } else {
	my $pdata = $packs->{$packid};
	if (($pdata->{'error'} || '') eq 'excluded') {
	  $reason = 'excluded';
	} else {
	  my %info = map {$_->{'repository'} => $_} @{$pdata->{'info'} || []};
	  my $info = $info{$repoid};
	  next unless $info && ($info->{'error'} || '') eq 'excluded';
	  $reason = 'excluded';
	}
      }
      my $gdst = "$reporoot/$prp/$myarch";
      my @files = ls("$gdst/$packid");
      my @ifiles = grep {/^::import::/ || /^\.meta\.success\.import\./} @files;
      if (@ifiles) {
	# only imported stuff?
        next unless grep {$_ ne '.bininfo' && !(/^::import::/ || /^\.meta\.success\.import\./)} @files;
      }
      print "      - $packid: is $reason\n";
      delete $lastcheck{$prp}->{$packid};
      # delete full entries
      my $useforbuildenabled = 1;
      $useforbuildenabled = BSUtil::enabled($repoid, $projpacks->{$projid}->{'useforbuild'}, $useforbuildenabled, $myarch);
      # hmm, need to exclude patchinfos here. cheating.
      $useforbuildenabled = 0 if -s "$gdst/$packid/.updateinfodata";
      # don't wipe imports if we're excluded
      my $importarch = $packs->{$packid} && @ifiles ? '' : undef;
      BSSched::BuildResult::update_dst_full($gctx, $prp, $packid, undef, undef, $useforbuildenabled, $prpsearchpath, undef, $importarch);
      $changed_med{$prp} = 2;
      BSSched::Events::sendrepochangeevent($gctx, $prp);
      # delete other files
      unlink("$gdst/:logfiles.success/$packid");
      unlink("$gdst/:logfiles.fail/$packid");
      unlink("$gdst/:meta/$packid");
      if (@ifiles) {
        for (@files) {
	  next if $_ eq '.bininfo';
	  next if /^::import::/ || /^\.meta\.success\.import\./;
          unlink("$gdst/$packid/$_");
	}
      } else {
        BSUtil::cleandir("$gdst/$packid");
      }
      rmdir("$gdst/$packid");
      BSSched::BuildJob::killbuilding($gctx, $prp, $packid);
      unlink("$reporoot/$prp/$myarch/:repodone");
    }


    # Step 2b: set up pool and repositories
    my $pool = BSSolv::pool->new();
    $pool->settype('deb') if $bconf->{'binarytype'} eq 'deb';
    $ctx->{'pool'} = $pool;

    my %building;
    my %dep2src;
    my %dep2pkg;
    my %depislocal;	# used in meta calculation
    my $error;
    my %unfinished;	# is blocked or needs rebuild
    my %notready;		# unfinished and will modify :full
    my $prpnotready = $gctx->{'prpnotready'};

    my $delayed;
    for my $rprp (@$prpsearchpath) {
      if (!BSSched::Access::checkprpaccess($gctx, $rprp, $prp)) {
	$error = "repository '$rprp' is unavailable";
	last;
      }
      my $r = BSSched::BuildRepo::addrepo($ctx, $pool, $rprp);
      if (!$r) {
	$delayed = 1 if defined $r;
	$error = "repository '$rprp' is unavailable";
	last;
      }
    }
    if ($error) {
      print "    $error\n";
      print "    (delayed)\n" if $delayed;
      $ctx->{'havedelayed'} = 1 if $delayed;
      set_repo_state($gctx, $prp, 'broken', $error) unless $delayed;
      next;
    }
    
    $pool->createwhatprovides();
    for my $p ($pool->consideredpackages()) {
      my $rprp = $pool->pkg2reponame($p);
      my $n = $pool->pkg2name($p);
      my $sn = $pool->pkg2srcname($p) || $n;
      $dep2pkg{$n} = $p;
      $dep2src{$n} = $sn;
      if ($rprp eq $prp) {
	$depislocal{$n} = 1;
      } else {
	$notready{$sn} = 2 if $prpnotready->{$rprp} && $prpnotready->{$rprp}->{$sn};
      }
    }
    $ctx->{'building'} = \%building;
    $ctx->{'notready'} = \%notready;
    $ctx->{'dep2pkg'} = \%dep2pkg;
    $ctx->{'dep2src'} = \%dep2src;
    $ctx->{'depislocal'} = \%depislocal;

    if ($repo->{'block'} && $repo->{'block'} eq 'local') {
      for (keys %notready) {
	delete $notready{$_} if $notready{$_} == 2;
      }
    }

    my $xp = BSSolv::expander->new($pool, $bconf);
    no warnings 'redefine';
    local *Build::expand = sub { $_[0] = $xp; goto &BSSolv::expander::expand; };
    use warnings 'redefine';

    my $prpchecktime = time();

    if ($bconf->{'expandflags:preinstallexpand'}) {
      my $err;
      if (!defined &Build::expandpreinstalls($bconf)) {
	$err = "Build::expandpreinstalls does not exist";
      } else {
	$err = Build::expandpreinstalls($bconf);
	$err = "unresolvable $err" if $err;
      }
      if ($err) {
        print "    $err\n";
        set_repo_state($gctx, $prp, 'broken', $err);
        next;
      }
    }
    # Step 2c: expand all dependencies, put them in %pdeps hash
    my %subpacks;
    push @{$subpacks{$dep2src{$_}}}, $_ for keys %dep2src;
    print "    expanding dependencies\n";
    my %experrors;
    $ctx->{'subpacks'} = \%subpacks;

    my %pdeps;
    my %pkg2src;
    my %pkgdisabled;
    my %havepatchinfos;
    my %pkg2buildtype;
    for my $packid (@packs) {
      my $pdata = $packs->{$packid};

      if ($pdata->{'error'} && $pdata->{'error'} eq 'excluded') {
	$pdeps{$packid} = [];
	next;
      }

      my $info = (grep {$_->{'repository'} eq $repoid} @{$pdata->{'info'} || []})[0];

      # calculate package type
      my $buildtype;
      if ($pdata->{'aggregatelist'}) {
	$buildtype = 'aggregate';
      } elsif ($pdata->{'patchinfo'}) {
	$buildtype = 'patchinfo';
      } elsif ($pdata->{'channel'}) {
	$buildtype = 'channel';
      } elsif ($info && $info->{'file'}) {
        # directly implement most common types
	if ($info->{'file'} =~ /\.(spec|dsc|kiwi|livebuild)$/) {
	  $buildtype = $1;
	  if ($buildtype eq 'kiwi') {
	    $buildtype = $info->{'imagetype'} && $info->{'imagetype'}->[0] eq 'product' ? 'kiwi-product' : 'kiwi-image';
	  }
	} else {
	  $buildtype = Build::recipe2buildtype($info->{'file'}) || 'unknown';
	}
      } else {
        $buildtype = 'unknown';
      }
      $pkg2buildtype{$packid} = $buildtype;
      $havepatchinfos{$packid} = 1 if $buildtype eq 'patchinfo';

      if (!$info || !defined($info->{'file'}) || !defined($info->{'name'})) {
	if ($pdata->{'error'} && $pdata->{'error'} eq 'disabled') {
	  $pkgdisabled{$packid} = 1;
	}
	if ($info && $info->{'error'} && $info->{'error'} eq 'disabled') {
	  $pkgdisabled{$packid} = 1;
	}
	$pdeps{$packid} = [];
	next;
      }
      if ($info->{'error'} && $info->{'error'} eq 'excluded') {
	$pdeps{$packid} = [];
	next;
      }
      if (exists($pdata->{'originproject'})) {
	# this is a package from a project link
	if (!$repo->{'linkedbuild'} || ($repo->{'linkedbuild'} ne 'localdep' && $repo->{'linkedbuild'} ne 'all')) {
	  $pdeps{$packid} = [];
	  next;
	}
      }
      $pkg2src{$packid} = $info->{'name'};

      if ($pdata->{'hasbuildenv'}) {
        $pdeps{$packid} = [];
        next;
      }
      my @deps = @{$info->{'dep'} || []};
      my $handler = $handlers{$buildtype} || $defaulthandler;
      my ($eok, @edeps) = $handler->expand($bconf, $subpacks{$info->{'name'}}, @deps);
      if (!$eok) {
	$experrors{$packid} = join(', ', @edeps) || '?';
	@edeps = @deps;
      }
      $pdeps{$packid} = \@edeps;
    }
    $ctx->{'edeps'} = \%pdeps;

    # sort packages by pdeps
    print "    sorting ".@packs." packages\n";
    my @cycles;
    if (@packs > 1) {
      @packs = BSSolv::depsort(\%pdeps, \%dep2src, \@cycles, @packs);
      if (@cycles) {
        print "cycle: ".join(' -> ', @$_)."\n" for @cycles;
      }
    }
    if (%havepatchinfos) {
      # bring patchinfos to back
      my @packs_patchinfos = grep {$havepatchinfos{$_}} @packs;
      @packs = grep {!$havepatchinfos{$_}} @packs;
      push @packs, @packs_patchinfos;
    }

    # write dependency information
    if (%pkgdisabled) {
      # leave info of disabled packages untouched
      my $olddepends = BSUtil::retrieve("$reporoot/$prp/$myarch/:depends", 1);
      if ($olddepends) {
	for (keys %pkgdisabled) {
	  $pdeps{$_} = $olddepends->{'pkgdeps'}->{$_} if $olddepends->{'pkgdeps'}->{$_};
	  $pkg2src{$_} = $olddepends->{'pkg2src'}->{$_} if $olddepends->{'pkg2src'}->{$_};
	}
      }
    }
    my %prunedsubpacks;
    for (values %pkg2src) {
      $prunedsubpacks{$_} = $subpacks{$_} if $subpacks{$_};
    }
    BSUtil::store("$reporoot/$prp/$myarch/.:depends", "$reporoot/$prp/$myarch/:depends", {
      'pkgdeps' => \%pdeps,
      'subpacks' => \%prunedsubpacks,
      'pkg2src' => \%pkg2src,
      'cycles' => \@cycles,
    });
    %prunedsubpacks = ();
    # remove old entries again
    for (keys %pkgdisabled) {
      $pdeps{$_} = [];
      delete $pkg2src{$_};
    }

    # now build cychash mapping packages to all other cycle members
    my %cychash;
    if (@cycles) {
      for my $cyc (@cycles) {
	my %nc = map {$_ => 1} @$cyc;
	for my $p (@$cyc) {
	  next unless $cychash{$p};
	  $nc{$_} = 1 for @{$cychash{$p}};
	}
	my $c = [ sort keys %nc ];
	$cychash{$_} = $c for @$c;
      }
    }

    my $projbuildenabled = 1;
    $projbuildenabled = BSUtil::enabled($repoid, $projpacks->{$projid}->{'build'}, 1, $myarch) if $projpacks->{$projid}->{'build'};
    my $projlocked = 0;
    $projlocked = BSUtil::enabled($repoid, $projpacks->{$projid}->{'lock'}, 0, $myarch) if $projpacks->{$projid}->{'lock'};

    # fetch relsync data
    my $relsyncmax;
    my %relsynctrigger;

    if (-s "$reporoot/$prp/$myarch/:relsync.max") {
      $relsyncmax = BSUtil::retrieve("$reporoot/$prp/$myarch/:relsync.max", 2);
      if ($relsyncmax && -s "$reporoot/$prp/$myarch/:relsync") {
	my $relsync = BSUtil::retrieve("$reporoot/$prp/$myarch/:relsync", 2);
	for my $packid (@packs) {
	  my $tag = $packs->{$packid}->{'bcntsynctag'} || $packid;
	  next unless $relsync->{$packid};
	  next unless $relsync->{$packid} =~ /(.*)\.(\d+)$/;
	  next unless defined($relsyncmax->{"$tag/$1"}) && $2 < $relsyncmax->{"$tag/$1"};
	  $relsynctrigger{$packid} = 1;
	}
      }
      if (%relsynctrigger) {
	# filter failed packages
	for (ls("$reporoot/$prp/$myarch/:logfiles.fail")) {
	  delete $relsynctrigger{$_};
	}
      }
    }
    $ctx->{'relsynctrigger'} = \%relsynctrigger;
    $ctx->{'relsyncmax'} = $relsyncmax;

    # Step 2d: check status of all packages
    my %packstatus;
    my $oldpackstatus;
    my %packerror;
    my @cpacks = @packs;
    my %cycpass;
    my $needed;
    $ctx->{'packstatus'} = \%packstatus;
    $ctx->{'cychash'} = \%cychash;
    $ctx->{'cycpass'} = \%cycpass;
    $ctx->{'nharder'} = 0;

    my $prjuseforbuildenabled = 1;
    $prjuseforbuildenabled = BSUtil::enabled($repoid, $projpacks->{$projid}->{'useforbuild'}, $prjuseforbuildenabled, $myarch);

    # copy old data over if we have missing packages
    if ($projpacks->{$projid}->{'missingpackages'}) {
      BSSched::Remote::addretryevent($gctx, {'type' => 'package', 'project' => $projid});
      $oldpackstatus = BSUtil::retrieve("$reporoot/$prp/$myarch/:packstatus", 1) || {};
      $oldpackstatus->{'packstatus'} ||= {};
      $oldpackstatus->{'packerror'} ||= {};
      for my $packid (keys %{$oldpackstatus->{'packstatus'}}) {
	next if $packs->{$packid};
	$packstatus{$packid} = $oldpackstatus->{'packstatus'}->{$packid};
	$packerror{$packid} = $oldpackstatus->{'packerror'}->{$packid} if $oldpackstatus->{'packerror'}->{$packid}; 
      }
    }

    while (@cpacks) {
      my $packid = shift @cpacks;
      my $incycle = 0;
      if ($cychash{$packid}) {
	next if $packstatus{$packid} && $packstatus{$packid} ne 'done'; # already decided in phase 1
	# cycle package, we look at a cycle two times:
	# 1) just trigger package builds caused by source changes
	# 2) normal package build triggering
	# cychash contains all packages of this cycle

	# calculate phase 1 packages
	my @cnext = grep {!$cycpass{$_}} @{$cychash{$packid}};
	if (@cnext) {
	  # still phase1 packages left, do them first
	  unshift @cpacks, $packid;
	  $packid = shift @cnext;
	  $cycpass{$packid} = 1;	# now doinig phase 1
	  $incycle = 1;
	} elsif (($cycpass{$packid} || 0) < 2) {
	  # enter phase 2
	  $cycpass{$packid} = 2;	# just in case...
	  my $pass = 2;
	  # we are building packages because of source changes,
	  # set cycpass to 3 so that we don't start other builds
	  $pass = 3 if grep {$building{$_}} @{$cychash{$packid}};
	  $cycpass{$_} = $pass for @{$cychash{$packid}};
	}
      }
      $ctx->{'incycle'} = $incycle;

      # product definitions are never building themself
      if ($packid eq '_product') {
	$packstatus{$packid} = 'excluded';
	next;
      }

      my $pdata = $packs->{$packid};
      if ($pdata->{'lock'}) {
	if (BSUtil::enabled($repoid, $pdata->{'lock'}, $projlocked, $myarch)) {
	  $packstatus{$packid} = 'locked';
	  next;
	}
      } else {
	if ($projlocked) {
	  $packstatus{$packid} = 'locked';
	  next;
	}
      }

      if ($pdata->{'error'}) {
	if ($pdata->{'error'} eq 'disabled' || $pdata->{'error'} eq 'excluded') {
	  $packstatus{$packid} = $pdata->{'error'};
	  next;
	}
	print "      - $packid ($pdata->{'error'})\n";
	if ($pdata->{'error'} =~ /download in progress/) {
	  $packstatus{$packid} = 'blocked';
	  $packerror{$packid} = $pdata->{'error'};
	  next;
	}
	if ($pdata->{'error'} =~ /source update running/ || $pdata->{'error'} =~ /service in progress/) {
	  $packstatus{$packid} = 'blocked';
	  $packerror{$packid} = $pdata->{'error'};
	  next;
	}
	if ($pdata->{'error'} eq 'delayed startup' || $pdata->{'error'} =~ /interconnect error:/) {
	  BSSched::Remote::addretryevent($gctx, {'type' => 'package', 'project' => $projid, 'package' => $packid});
	  $ctx->{'havedelayed'} = 1;
	  $packstatus{$packid} = 'blocked';
	  $packerror{$packid} = $pdata->{'error'};
	  next;
	}
	$packstatus{$packid} = 'broken';
	$packerror{$packid} = $pdata->{'error'};
	next;
      }

      if (exists($pdata->{'originproject'})) {
	# this is a package from a project link
	if (!$repo->{'linkedbuild'} || ($repo->{'linkedbuild'} ne 'localdep' && $repo->{'linkedbuild'} ne 'all')) {
	  $packstatus{$packid} = 'excluded';
	  $packerror{$packid} = 'project link';
	  next;
	}
      }

      if ($pdata->{'build'}) {
	if (!BSUtil::enabled($repoid, $pdata->{'build'}, $projbuildenabled, $myarch)) {
	  $packstatus{$packid} = 'disabled';
	  next;
	}
      } else {
	if (!$projbuildenabled) {
	  $packstatus{$packid} = 'disabled';
	  next;
	}
      }

      # select correct info again
      my $info = (grep {$_->{'repository'} eq $repoid} @{$pdata->{'info'} || []})[0] || {};

      # name of src package, needed for block detection
      my $pname = $info->{'name'} || $packid;

      if ($info->{'error'}) {
	if ($info->{'error'} eq 'disabled' || $info->{'error'} eq 'excluded') {
	  $packstatus{$packid} = $info->{'error'};
	  next;
	}
	print "      - $packid ($info->{'error'})\n";
	$packstatus{$packid} = 'broken';
	$packerror{$packid} = $info->{'error'};
	next;
      }

      # calculate package build type
      my $buildtype = $pkg2buildtype{$packid} || 'unknown';
      if ($buildtype eq 'unknown') {
	print "      - $packid (no recipe file)\n";
	$packstatus{$packid} = 'broken';
	$packerror{$packid} = 'no recipe file';
	next;
      }
      my $handler = $handlers{$buildtype} || $defaulthandler;
      #print "      - $packid ($buildtype)\n";

      if (!$incycle) {
	# hmm, this might be a bad idea...
	my $job = BSSched::BuildJob::jobname($prp, $packid)."-$pdata->{'srcmd5'}";
	my $myjobsdir = $gctx->{'myjobsdir'};
	if (-s "$myjobsdir/$job") {
	  # print "      - $packid ($buildtype)\n";
	  # print "        already scheduled\n";
	  BSSched::BuildJob::add_crossmarker($gctx, $bconf->{'hostarch'}, $job) if $bconf->{'hostarch'};
	  my $useforbuildenabled = BSUtil::enabled($repoid, $pdata->{'useforbuild'}, $prjuseforbuildenabled, $myarch);
	  $building{$packid} = $job;
	  $notready{$pname} = 1 if $useforbuildenabled;
	  $unfinished{$pname} = 1;
	  $packstatus{$packid} = 'scheduled';
	  next;
	}
      }

      # now print expandsion errors
      if ($experrors{$packid}) {
	print "      - $packid ($buildtype)\n";
	print "        unresolvable:\n";
	print "            $experrors{$packid}\n";
	$packstatus{$packid} = 'unresolvable';
	$packerror{$packid} = $experrors{$packid};
	next;
      }

      # dispatch to handlers
      my ($astatus, $aerror) = $handler->check($ctx, $packid, $pdata, $info, $buildtype);
      if ($astatus eq 'scheduled') {
	# aerror contains rebuild data in this case
	($astatus, $aerror) = $handler->build($ctx, $packid, $pdata, $info, $aerror);
	if ($astatus eq 'scheduled') {
	  $building{$packid} = $aerror || 'job'; # aerror contains jobid in this case
	  undef $aerror;
	} elsif ($astatus eq 'delayed') {
          $ctx->{'havedelayed'} = 1;
	  ($astatus, $aerror) = ('blocked', defined($aerror) ? "delayed: $aerror" : 'delayed');
	}
	unlink("$reporoot/$prp/$myarch/:repodone");
      } elsif ($astatus eq 'delayed') {
        $ctx->{'havedelayed'} = 1;
	if (!$oldpackstatus) {
	  $oldpackstatus = BSUtil::retrieve("$reporoot/$prp/$myarch/:packstatus", 1) || {};
	  $oldpackstatus->{'packstatus'} ||= {};
	  $oldpackstatus->{'packerror'} ||= {};
	}
	$astatus = $oldpackstatus->{'packstatus'}->{$packid};
	$aerror = $oldpackstatus->{'packerror'}->{$packid};
	($astatus, $aerror) = ('blocked', 'delayed') unless $astatus;
	$unfinished{$pname} = 1;
      }
      $packstatus{$packid} = $astatus;
      $packerror{$packid} = $aerror if defined $aerror;
      if ($astatus eq 'blocked' || $astatus eq 'scheduled') {
	my $useforbuildenabled = BSUtil::enabled($repoid, $pdata->{'useforbuild'}, $prjuseforbuildenabled, $myarch);
	$notready{$pname} = 1 if $useforbuildenabled;
	$unfinished{$pname} = 1;
      }
    }

    # delete global entries from notready
    for (keys %notready) {
      delete $notready{$_} if $notready{$_} == 2;
    }
    # put local notready into prpnotready if not a leaf
    if (%notready && $gctx->{'prpnoleaf'}->{$prp}) {
      $prpnotready->{$prp} = \%notready;
    } else {
      delete $prpnotready->{$prp};
    }

    # write blocked data into a file so that remote servers can fetch it
    # we don't put it into :packstatus to make retrival fast
    if (%notready) {
      my @blocked = sort keys %notready;
      writexml("$reporoot/$prp/$myarch/.:repostate", "$reporoot/$prp/$myarch/:repostate", {'blocked' => \@blocked}, $BSXML::repositorystate);
    } else {
      unlink("$reporoot/$prp/$myarch/:repostate");
    }

    # building jobs may have changed back to excluded, blocked or disabled, remove the jobs
    BSSched::BuildJob::killunwantedjobs($ctx->{'gctx'}, $prp, \%packstatus);

    # notify remote build services of repository changes or block state
    # changes
    # we alse send it if we finish a prp to give linked aggregates a
    # chance to work
    my $repounchanged = $gctx->{'repounchanged'};
    if (!$repounchanged->{$prp} || (!%unfinished && !$gctx->{'prpfinished'}->{$prp})) {
      BSSched::Events::sendrepochangeevent($gctx, $prp);
      $repounchanged->{$prp} = 1;
    } elsif ($repounchanged->{$prp} == 2) {
      BSSched::Events::sendrepochangeevent($gctx, $prp, 'repoinfo');
      $repounchanged->{$prp} = 1;
    }

    # free memory
    Build::forgetdeps($bconf);

    # write package status for this project
    BSUtil::store("$reporoot/$prp/$myarch/.:packstatus", "$reporoot/$prp/$myarch/:packstatus", {
      'packstatus' => \%packstatus,
      'packerror' => \%packerror,
    });
    unlink("$reporoot/$prp/$myarch/:packstatus.finished");

    $prpchecktime = time() - $prpchecktime;

    # write some stats
    for my $status (sort keys %{{map {$_ => 1} values %packstatus}}) {
      print "    $status: ".scalar(grep {$_ eq $status} values %packstatus)."\n";
    }
    print "    looked harder: $ctx->{'nharder'}\n" if $ctx->{'nharder'};
    print "    building: ".scalar(keys %building).", notready: ".scalar(keys %notready).", unfinished: ".scalar(keys %unfinished)."\n";
    print "    took $prpchecktime seconds to check the packages\n";

    # trigger dod package fetching
    if ($BSConfig::enable_download_on_demand) {
      BSSched::DoD::dodfetch($ctx) if $ctx->{'doddownloads'};
    }

    my $schedulerstate;
    my $schedulerdetails;
    if (keys %building) {
      $schedulerstate = 'building';
    } elsif ($ctx->{'havedelayed'} || keys %unfinished) {
      $schedulerstate = 'blocked';
    } else {
      $schedulerstate = 'finished';
    }

    # we always publish kiwi...
    if ((!%unfinished && !$ctx->{'havedelayed'}) || $prptype eq 'kiwi') {
      my $locked = 0;
      $locked = BSUtil::enabled($repoid, $projpacks->{$projid}->{'lock'}, $locked, $myarch) if $projpacks->{$projid}->{'lock'};
      my $pubenabled = BSUtil::enabled($repoid, $projpacks->{$projid}->{'publish'}, 1, $myarch);
      my %pubenabled;
      for my $packid (@packs) {
	my $pdata = $packs->{$packid};
        next if defined($pdata->{'lock'}) && BSUtil::enabled($repoid, $pdata->{'lock'}, $locked, $myarch);
        next if !defined($pdata->{'lock'}) && $locked;
	if ($pdata->{'publish'}) {
	  $pubenabled{$packid} = BSUtil::enabled($repoid, $pdata->{'publish'}, $pubenabled, $myarch);
	} else {
	  $pubenabled{$packid} = $pubenabled;
	}
      }
      my $repodonestate = $projpacks->{$projid}->{'patternmd5'} || '';
      for my $packid (@packs) {
	$repodonestate .= "\0$packid" if $pubenabled{$packid};
      }
      $repodonestate .= "\0$_" for sort keys %unfinished;
      $repodonestate = Digest::MD5::md5_hex($repodonestate);
      if (@packs && !grep {$_} values %pubenabled) {
	# all packages have publish disabled hint
	$repodonestate = "disabled:$repodonestate";
      }
      if (-e "$reporoot/$prp/$myarch/:repodone") {
	my $oldrepodone = readstr("$reporoot/$prp/$myarch/:repodone", 1) || '';
	unlink("$reporoot/$prp/$myarch/:repodone") if $oldrepodone ne $repodonestate;
      }
      my $publisherror;
      if ($locked) {
	print "    publishing is locked\n";
      } elsif (! -e "$reporoot/$prp/$myarch/:repodone") {
	if (($repodonestate !~ /^disabled/) || -d "$reporoot/$prp/$myarch/:repo") {
	  mkdir_p("$reporoot/$prp/$myarch");
	  $publisherror = BSSched::PublishRepo::prpfinished($ctx, \@packs, \%pubenabled);
	} else {
	  print "    publishing is disabled\n";
	}
	writestr("$reporoot/$prp/$myarch/:repodone", undef, $repodonestate) unless $publisherror || %unfinished;
        if ($publisherror) {
  	  $schedulerstate = "broken";
  	  $schedulerstate = "building" if $publisherror eq 'delta generation: building';
  	  $schedulerdetails = $publisherror;
        }
      }
      if (!%unfinished && !$publisherror) {
	$gctx->{'prpfinished'}->{$prp} = 1;
	# write out lastcheck cache and delete it
	if ($lastcheck{$prp} && %{$lastcheck{$prp}}) {
	  BSUtil::store("$reporoot/$prp/$myarch/.:lastcheck", "$reporoot/$prp/$myarch/:lastcheck", $lastcheck{$prp}) if $lastcheck{$prp};
	} else {
	  unlink("$reporoot/$prp/$myarch/:lastcheck");
	}
	delete $lastcheck{$prp};
	# delete pkg meta cache
	my $repodatas = $gctx->{'repodatas'};
	delete $repodatas->{$prp}->{'meta'} if $repodatas->{$prp};
	if (!$gctx->{'prpnoleaf'}->{$prp}) {
	  # only free repo data if all projects we depend on are finished, too.
	  # (we always have to do the expansion if something changes)
	  my @unfinishedprps;
	  my $remoteprojs = $gctx->{'remoteprojs'};
	  my $prpfinished = $gctx->{'prpfinished'};
	  for (@{$gctx->{'prpdeps'}->{$prp}}) {
	    next if $prpfinished->{$_};
	    # if this is a remote repo, check prpnotready
	    if (!%{$prpnotready->{$_} || {}}) {
	      my ($p) = split('/', $_, 2);
	      next if $remoteprojs->{$p};
	    }
	    push @unfinishedprps, $_;
	  }
	  if (!@unfinishedprps) {
	    print "    leaf prp, freeing data\n";
	    delete $repodatas->{$prp};
	  } else {
	    print "    leaf prp, unfinished prps: @unfinishedprps\n";
	  }
	}
      }
      # special handling for incidents, we need to guarantee that dirty flag of channel
      # are set in channel repos early enough or a release may be possible
      my $proj = $projpacks->{$projid} || {};
      if (($proj->{'kind'} || '') eq 'maintenance_incident') {
        my $prpfinished = $gctx->{'prpfinished'};
	for my $my_repo (@{$proj->{'repository'} ||[]}) {
          my $my_prp = "$projid/$my_repo->{'name'}";
	  next if $prpfinished->{$my_prp};
	  for (@{$gctx->{'prpdeps'}->{$my_prp}}) {
	    next if $prpfinished->{$_};
	    BSUtil::touch("$reporoot/$my_prp/$myarch/:schedulerstate.dirty") if -d "$reporoot/$my_prp/$myarch";
          }
        }
      }
    } else {
      delete $gctx->{'prpfinished'}->{$prp};
      unlink("$reporoot/$prp/$myarch/:repodone");
    }

    set_repo_state($gctx, $prp, $schedulerstate, $schedulerdetails);

    if (%unfinished) {
      $gctx->{'prpunfinished'}->{$prp} = scalar(keys %unfinished);
    } else {
      delete $gctx->{'prpunfinished'}->{$prp};
    }
    $gctx->{'prpchecktimes'}->{$prp} = $prpchecktime;

    # send relsync file if something has been changed
    my @relsync1 = stat("$reporoot/$prp/$myarch/:relsync");
    my @relsync2 = stat("$reporoot/$prp/$myarch/:relsync.sent");
    if (@relsync1 && (!@relsync2 || "$relsync1[9]/$relsync1[7]/$relsync1[1]" ne "$relsync2[9]/$relsync2[7]/$relsync2[1]")) {
      sendrelsyncupdate($gctx, $prp, %unfinished ? 0 : 1);
    }

    BSSched::Remote::cleanup_remotepackstatus($gctx, $prp) if $gctx->{'remotepackstatus_cleanup'}->{$prp} && !$ctx->{'havedelayed'};

    my $now = time();
    if ($prpchecktime) {
      $gctx->{'nextmed'}->{$prp} = $now + 10 * $prpchecktime;
    } else {
      delete $gctx->{'nextmed'}->{$prp};
    }
    $gctx->{'prplastcheck'}->{$prp} = $now;

    if ($now - $lastschedinfo > 60) {
      # update scheduler stats
      writeschedulerinfo($gctx);
      $lastschedinfo = $now;
    }
  }

};

if ($@) {
  warn($@);
  BSSched::Events::event_exit({ 'gctx' => $gctx }, {'type' => 'emergencydump'});
  exit(1);
}

exit(0);
